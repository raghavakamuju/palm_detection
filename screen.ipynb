{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pen lifted\n",
      "Pen lifted\n",
      "Pen lifted\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "canvas = np.ones((500, 500, 3), dtype=np.uint8) * 255\n",
    "color = (0, 0, 0)\n",
    "drawing = False\n",
    "\n",
    "\n",
    "def draw_circle(event, x, y, flags, param):\n",
    "    global drawing\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        cv2.circle(canvas, (x, y), 6, (0, 0, 0), 5, -1)\n",
    "    elif event == cv2.EVENT_MOUSEMOVE and drawing:\n",
    "        cv2.circle(canvas, (x, y), 5, color, -1)\n",
    "        \n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        print('Pen lifted')\n",
    "\n",
    "cv2.namedWindow('Color Painter')\n",
    "cv2.setMouseCallback('Color Painter', draw_circle)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow('Color Painter', canvas)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord('q'):  \n",
    "        break\n",
    "    elif key == ord('s'): \n",
    "        cv2.imwrite('output.jpg', canvas)\n",
    "\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading pytorch_model.bin:  82%|████████▏ | 807M/982M [05:40<01:13, 2.37MB/s] \n",
      "Downloading pytorch_model.bin:  26%|██▌       | 252M/982M [13:19<38:39, 315kB/s]  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not load model nlpconnect/vit-gpt2-image-captioning with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForVision2Seq'>, <class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForVision2Seq'>, <class 'transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel'>, <class 'transformers.models.vision_encoder_decoder.modeling_tf_vision_encoder_decoder.TFVisionEncoderDecoderModel'>). See the original errors:\n\nwhile loading with AutoModelForVision2Seq, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\response.py\", line 710, in _error_catcher\n    yield\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\response.py\", line 814, in _raw_read\n    data = self._fp_read(amt) if not fp_closed else b\"\"\n           ^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\response.py\", line 799, in _fp_read\n    return self._fp.read(amt) if amt is not None else self._fp.read()\n           ^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\http\\client.py\", line 466, in read\n    s = self.fp.read(amt)\n        ^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\socket.py\", line 706, in readinto\n    return self._sock.recv_into(b)\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\ssl.py\", line 1278, in recv_into\n    return self.read(nbytes, buffer)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\ssl.py\", line 1134, in read\n    return self._sslobj.read(len, buffer)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTimeoutError: The read operation timed out\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Python311\\Lib\\site-packages\\requests\\models.py\", line 816, in generate\n    yield from self.raw.stream(chunk_size, decode_content=True)\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\response.py\", line 940, in stream\n    data = self.read(amt=amt, decode_content=decode_content)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\response.py\", line 879, in read\n    data = self._raw_read(amt)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\response.py\", line 813, in _raw_read\n    with self._error_catcher():\n  File \"c:\\Python311\\Lib\\contextlib.py\", line 155, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\response.py\", line 715, in _error_catcher\n    raise ReadTimeoutError(self._pool, None, \"Read timed out.\") from e  # type: ignore[arg-type]\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nurllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\base.py\", line 269, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 563, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\vision_encoder_decoder\\modeling_vision_encoder_decoder.py\", line 363, in from_pretrained\n    return super().from_pretrained(pretrained_model_name_or_path, *model_args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\modeling_utils.py\", line 2805, in from_pretrained\n    resolved_archive_file = cached_file(\n                            ^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\hub.py\", line 429, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 118, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 1429, in hf_hub_download\n    http_get(\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 551, in http_get\n    for chunk in r.iter_content(chunk_size=10 * 1024 * 1024):\n  File \"c:\\Python311\\Lib\\site-packages\\requests\\models.py\", line 822, in generate\n    raise ConnectionError(e)\nrequests.exceptions.ConnectionError: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n\nwhile loading with TFAutoModelForVision2Seq, an error is thrown:\nTraceback (most recent call last):\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\base.py\", line 269, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 563, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\vision_encoder_decoder\\modeling_tf_vision_encoder_decoder.py\", line 336, in from_pretrained\n    return super().from_pretrained(pretrained_model_name_or_path, *model_args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\modeling_tf_utils.py\", line 2820, in from_pretrained\n    raise EnvironmentError(\nOSError: nlpconnect/vit-gpt2-image-captioning does not appear to have a file named tf_model.h5 but there is a file for PyTorch weights. Use `from_pt=True` to load this model from those weights.\n\nwhile loading with VisionEncoderDecoderModel, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\response.py\", line 710, in _error_catcher\n    yield\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\response.py\", line 814, in _raw_read\n    data = self._fp_read(amt) if not fp_closed else b\"\"\n           ^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\response.py\", line 799, in _fp_read\n    return self._fp.read(amt) if amt is not None else self._fp.read()\n           ^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\http\\client.py\", line 466, in read\n    s = self.fp.read(amt)\n        ^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\socket.py\", line 706, in readinto\n    return self._sock.recv_into(b)\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\ssl.py\", line 1278, in recv_into\n    return self.read(nbytes, buffer)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\ssl.py\", line 1134, in read\n    return self._sslobj.read(len, buffer)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTimeoutError: The read operation timed out\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Python311\\Lib\\site-packages\\requests\\models.py\", line 816, in generate\n    yield from self.raw.stream(chunk_size, decode_content=True)\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\response.py\", line 940, in stream\n    data = self.read(amt=amt, decode_content=decode_content)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\response.py\", line 879, in read\n    data = self._raw_read(amt)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\response.py\", line 813, in _raw_read\n    with self._error_catcher():\n  File \"c:\\Python311\\Lib\\contextlib.py\", line 155, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\response.py\", line 715, in _error_catcher\n    raise ReadTimeoutError(self._pool, None, \"Read timed out.\") from e  # type: ignore[arg-type]\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nurllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\base.py\", line 269, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\vision_encoder_decoder\\modeling_vision_encoder_decoder.py\", line 363, in from_pretrained\n    return super().from_pretrained(pretrained_model_name_or_path, *model_args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\modeling_utils.py\", line 2805, in from_pretrained\n    resolved_archive_file = cached_file(\n                            ^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\hub.py\", line 429, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 118, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 1429, in hf_hub_download\n    http_get(\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 551, in http_get\n    for chunk in r.iter_content(chunk_size=10 * 1024 * 1024):\n  File \"c:\\Python311\\Lib\\site-packages\\requests\\models.py\", line 822, in generate\n    raise ConnectionError(e)\nrequests.exceptions.ConnectionError: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n\nwhile loading with TFVisionEncoderDecoderModel, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\connection.py\", line 203, in _new_conn\n    sock = connection.create_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 60, in create_connection\n    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\socket.py\", line 962, in getaddrinfo\n    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nsocket.gaierror: [Errno 11001] getaddrinfo failed\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 790, in urlopen\n    response = self._make_request(\n               ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 491, in _make_request\n    raise new_e\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 467, in _make_request\n    self._validate_conn(conn)\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 1092, in _validate_conn\n    conn.connect()\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\connection.py\", line 611, in connect\n    self.sock = sock = self._new_conn()\n                       ^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\connection.py\", line 210, in _new_conn\n    raise NameResolutionError(self.host, self, e) from e\nurllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x0000012F6C62E790>: Failed to resolve 'huggingface.co' ([Errno 11001] getaddrinfo failed)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Python311\\Lib\\site-packages\\requests\\adapters.py\", line 486, in send\n    resp = conn.urlopen(\n           ^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 844, in urlopen\n    retries = retries.increment(\n              ^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 515, in increment\n    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /nlpconnect/vit-gpt2-image-captioning/resolve/main/pytorch_model.bin (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000012F6C62E790>: Failed to resolve 'huggingface.co' ([Errno 11001] getaddrinfo failed)\"))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\base.py\", line 269, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\vision_encoder_decoder\\modeling_tf_vision_encoder_decoder.py\", line 336, in from_pretrained\n    return super().from_pretrained(pretrained_model_name_or_path, *model_args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\modeling_tf_utils.py\", line 2819, in from_pretrained\n    if has_file(pretrained_model_name_or_path, WEIGHTS_NAME, **has_file_kwargs):\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\hub.py\", line 647, in has_file\n    r = requests.head(url, headers=headers, allow_redirects=False, proxies=proxies, timeout=10)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\requests\\api.py\", line 100, in head\n    return request(\"head\", url, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\requests\\api.py\", line 59, in request\n    return session.request(method=method, url=url, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\requests\\adapters.py\", line 519, in send\n    raise ConnectionError(e, request=request)\nrequests.exceptions.ConnectionError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /nlpconnect/vit-gpt2-image-captioning/resolve/main/pytorch_model.bin (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000012F6C62E790>: Failed to resolve 'huggingface.co' ([Errno 11001] getaddrinfo failed)\"))\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m----> 2\u001b[0m image_to_text \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage-to-text\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnlpconnect/vit-gpt2-image-captioning\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m lis1\u001b[38;5;241m=\u001b[39mimage_to_text(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://ankur3107.github.io/assets/images/image-captioning-example.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m lis1[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\__init__.py:824\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    823\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[1;32m--> 824\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m    835\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\base.py:282\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m class_name, trace \u001b[38;5;129;01min\u001b[39;00m all_traceback\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    281\u001b[0m             error \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile loading with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, an error is thrown:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtrace\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 282\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    283\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not load model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with any of the following classes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_tuple\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. See the original errors:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m         )\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    287\u001b[0m     framework \u001b[38;5;241m=\u001b[39m infer_framework(model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Could not load model nlpconnect/vit-gpt2-image-captioning with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForVision2Seq'>, <class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForVision2Seq'>, <class 'transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel'>, <class 'transformers.models.vision_encoder_decoder.modeling_tf_vision_encoder_decoder.TFVisionEncoderDecoderModel'>). See the original errors:\n\nwhile loading with AutoModelForVision2Seq, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\response.py\", line 710, in _error_catcher\n    yield\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\response.py\", line 814, in _raw_read\n    data = self._fp_read(amt) if not fp_closed else b\"\"\n           ^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\response.py\", line 799, in _fp_read\n    return self._fp.read(amt) if amt is not None else self._fp.read()\n           ^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\http\\client.py\", line 466, in read\n    s = self.fp.read(amt)\n        ^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\socket.py\", line 706, in readinto\n    return self._sock.recv_into(b)\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\ssl.py\", line 1278, in recv_into\n    return self.read(nbytes, buffer)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\ssl.py\", line 1134, in read\n    return self._sslobj.read(len, buffer)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTimeoutError: The read operation timed out\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Python311\\Lib\\site-packages\\requests\\models.py\", line 816, in generate\n    yield from self.raw.stream(chunk_size, decode_content=True)\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\response.py\", line 940, in stream\n    data = self.read(amt=amt, decode_content=decode_content)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\response.py\", line 879, in read\n    data = self._raw_read(amt)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\response.py\", line 813, in _raw_read\n    with self._error_catcher():\n  File \"c:\\Python311\\Lib\\contextlib.py\", line 155, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\response.py\", line 715, in _error_catcher\n    raise ReadTimeoutError(self._pool, None, \"Read timed out.\") from e  # type: ignore[arg-type]\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nurllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\base.py\", line 269, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 563, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\vision_encoder_decoder\\modeling_vision_encoder_decoder.py\", line 363, in from_pretrained\n    return super().from_pretrained(pretrained_model_name_or_path, *model_args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\modeling_utils.py\", line 2805, in from_pretrained\n    resolved_archive_file = cached_file(\n                            ^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\hub.py\", line 429, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 118, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 1429, in hf_hub_download\n    http_get(\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 551, in http_get\n    for chunk in r.iter_content(chunk_size=10 * 1024 * 1024):\n  File \"c:\\Python311\\Lib\\site-packages\\requests\\models.py\", line 822, in generate\n    raise ConnectionError(e)\nrequests.exceptions.ConnectionError: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n\nwhile loading with TFAutoModelForVision2Seq, an error is thrown:\nTraceback (most recent call last):\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\base.py\", line 269, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 563, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\vision_encoder_decoder\\modeling_tf_vision_encoder_decoder.py\", line 336, in from_pretrained\n    return super().from_pretrained(pretrained_model_name_or_path, *model_args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\modeling_tf_utils.py\", line 2820, in from_pretrained\n    raise EnvironmentError(\nOSError: nlpconnect/vit-gpt2-image-captioning does not appear to have a file named tf_model.h5 but there is a file for PyTorch weights. Use `from_pt=True` to load this model from those weights.\n\nwhile loading with VisionEncoderDecoderModel, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\response.py\", line 710, in _error_catcher\n    yield\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\response.py\", line 814, in _raw_read\n    data = self._fp_read(amt) if not fp_closed else b\"\"\n           ^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\response.py\", line 799, in _fp_read\n    return self._fp.read(amt) if amt is not None else self._fp.read()\n           ^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\http\\client.py\", line 466, in read\n    s = self.fp.read(amt)\n        ^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\socket.py\", line 706, in readinto\n    return self._sock.recv_into(b)\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\ssl.py\", line 1278, in recv_into\n    return self.read(nbytes, buffer)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\ssl.py\", line 1134, in read\n    return self._sslobj.read(len, buffer)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTimeoutError: The read operation timed out\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Python311\\Lib\\site-packages\\requests\\models.py\", line 816, in generate\n    yield from self.raw.stream(chunk_size, decode_content=True)\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\response.py\", line 940, in stream\n    data = self.read(amt=amt, decode_content=decode_content)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\response.py\", line 879, in read\n    data = self._raw_read(amt)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\response.py\", line 813, in _raw_read\n    with self._error_catcher():\n  File \"c:\\Python311\\Lib\\contextlib.py\", line 155, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\response.py\", line 715, in _error_catcher\n    raise ReadTimeoutError(self._pool, None, \"Read timed out.\") from e  # type: ignore[arg-type]\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nurllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\base.py\", line 269, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\vision_encoder_decoder\\modeling_vision_encoder_decoder.py\", line 363, in from_pretrained\n    return super().from_pretrained(pretrained_model_name_or_path, *model_args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\modeling_utils.py\", line 2805, in from_pretrained\n    resolved_archive_file = cached_file(\n                            ^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\hub.py\", line 429, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 118, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 1429, in hf_hub_download\n    http_get(\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 551, in http_get\n    for chunk in r.iter_content(chunk_size=10 * 1024 * 1024):\n  File \"c:\\Python311\\Lib\\site-packages\\requests\\models.py\", line 822, in generate\n    raise ConnectionError(e)\nrequests.exceptions.ConnectionError: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n\nwhile loading with TFVisionEncoderDecoderModel, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\connection.py\", line 203, in _new_conn\n    sock = connection.create_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 60, in create_connection\n    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\socket.py\", line 962, in getaddrinfo\n    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nsocket.gaierror: [Errno 11001] getaddrinfo failed\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 790, in urlopen\n    response = self._make_request(\n               ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 491, in _make_request\n    raise new_e\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 467, in _make_request\n    self._validate_conn(conn)\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 1092, in _validate_conn\n    conn.connect()\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\connection.py\", line 611, in connect\n    self.sock = sock = self._new_conn()\n                       ^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\connection.py\", line 210, in _new_conn\n    raise NameResolutionError(self.host, self, e) from e\nurllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x0000012F6C62E790>: Failed to resolve 'huggingface.co' ([Errno 11001] getaddrinfo failed)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Python311\\Lib\\site-packages\\requests\\adapters.py\", line 486, in send\n    resp = conn.urlopen(\n           ^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 844, in urlopen\n    retries = retries.increment(\n              ^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 515, in increment\n    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /nlpconnect/vit-gpt2-image-captioning/resolve/main/pytorch_model.bin (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000012F6C62E790>: Failed to resolve 'huggingface.co' ([Errno 11001] getaddrinfo failed)\"))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\base.py\", line 269, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\vision_encoder_decoder\\modeling_tf_vision_encoder_decoder.py\", line 336, in from_pretrained\n    return super().from_pretrained(pretrained_model_name_or_path, *model_args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\modeling_tf_utils.py\", line 2819, in from_pretrained\n    if has_file(pretrained_model_name_or_path, WEIGHTS_NAME, **has_file_kwargs):\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ragha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\hub.py\", line 647, in has_file\n    r = requests.head(url, headers=headers, allow_redirects=False, proxies=proxies, timeout=10)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\requests\\api.py\", line 100, in head\n    return request(\"head\", url, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\requests\\api.py\", line 59, in request\n    return session.request(method=method, url=url, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\requests\\adapters.py\", line 519, in send\n    raise ConnectionError(e, request=request)\nrequests.exceptions.ConnectionError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /nlpconnect/vit-gpt2-image-captioning/resolve/main/pytorch_model.bin (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000012F6C62E790>: Failed to resolve 'huggingface.co' ([Errno 11001] getaddrinfo failed)\"))\n\n\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "image_to_text = pipeline(\"image-to-text\", model=\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "lis1=image_to_text(\"https://ankur3107.github.io/assets/images/image-captioning-example.png\")\n",
    "lis1[0]['generated_text']\n",
    "print(lis1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
